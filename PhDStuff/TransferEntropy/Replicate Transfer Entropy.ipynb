{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating Transfer Entropy Code in Python\n",
    "\n",
    "In Anderson and McMullin, \"Detecting Information Flows in Markets\" 2018 **[1]**. They compute Transfer Entropy using Kraskov, A., H. Stogbauer, and P. Grassberger (2004, Jun). Estimating mutual information. Phys. Rev. E 69, 066138 **[2]**.\n",
    "\n",
    "McMullin referred us to the implementation of **[2]** that they use which is here: https://github.com/Healthcast/TransEnt/blob/master/src/compute_TE.cpp. McMullin recommended that we use to the MI_diff function in the compute_TE.cpp file because it is better empirically and theoretically.\n",
    "\n",
    "The rest of this notebook implements compute_TE.cpp using the sample data that McMullin sent us which can be found here: https://uofi.box.com/s/ror93i0ed7ky4hzn38ljyc22i5o0p4zd. \n",
    "\n",
    "----\n",
    "**Note:** To gain access to the sample data contact either: ikegwu2 [at] illinois or bigdog [at] illinois\n",
    "\n",
    "----\n",
    "The code cell below imports libraries needed for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np  # to handle data\n",
    "import pandas as pd  # to handle data\n",
    "import os  # to handle manipulation of files\n",
    "from sklearn.neighbors import KDTree  # to compute distance\n",
    "\n",
    "from nose.tools import assert_true  # To check certain operations\n",
    "from numpy.testing import assert_array_equal  # To check certain operations\n",
    "from scipy.special import digamma  # to compute log derivative of gamma function\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below will obtain the file names from the sample data and output the first 10 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files: ['SPY_US_09_21_18_C100_Equity_ask.dat', 'SPY_US_09_21_18_C100_Equity_bid.dat', 'SPY_US_09_21_18_C100_Equity_last.dat', 'SPY_US_09_21_18_C105_Equity_ask.dat', 'SPY_US_09_21_18_C105_Equity_bid.dat', 'SPY_US_09_21_18_C105_Equity_last.dat', 'SPY_US_09_21_18_C115_Equity_ask.dat', 'SPY_US_09_21_18_C115_Equity_bid.dat', 'SPY_US_09_21_18_C115_Equity_last.dat']\n"
     ]
    }
   ],
   "source": [
    "# Directory where data is stored\n",
    "dir_path = '/Users/jarvis/Downloads/spy_09_21_18_updated/'  # Yes my computer's name is jarvis\n",
    "\n",
    "files = os.listdir(dir_path)  # Grab files in directory\n",
    "print(\"Files:\", sorted(files)[0:9])  # display first 10 files\n",
    "transfer_entropy = {}  # contains values for transfer entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing the File Names & Data: \n",
    "\n",
    "\n",
    "1. This filename: \"SPY_US_09_21_18_C100_Equity_ask.dat\": contains the prices for the SPY security and the Call option with a strike price of $100. The date is 09.21.2018. The Prices are recorded from bloomberg's ask variable. The prices are measured at every two seconds. The file has 2 columns where the first column is the price of the scurity and the second column is the price of the optional.\n",
    "\n",
    "2. This filename: \"SPY_US_09_21_18_C100_Equity_bid.dat\" contains the same information as the first item except the prices are recorded from bloomberg's bid variable.\n",
    "\n",
    "3. This filename: \"SPY_US_09_21_18_C100_Equity_last.dat\" contains the same information as the first & second items except the prices are recorded from bloomberg's last variable.\n",
    "\n",
    "Generally you have 3 files for a particular stike price.\n",
    "\n",
    "-----\n",
    "\n",
    "__Note:__ Ask Jeff about Bloomberg data, in particular some reference for description of data. I cannot find any offical documentation so I assume that bid is the max price that a buyer is willing to pay for a security, ask is the min price that a seller is willing to recieve for selling a security and last is simply the price at which the last trade occurred.\n",
    "\n",
    "-----\n",
    "\n",
    "We'll work with 1 file for now and then eventually apply the concepts presented below to all of data. The code cell below reads in data for: \"SPY_US_09_21_18_C100_Equity_ask.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>security price</th>\n",
       "      <th>option price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>286.99</td>\n",
       "      <td>187.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>287.00</td>\n",
       "      <td>187.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>286.99</td>\n",
       "      <td>187.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>287.00</td>\n",
       "      <td>188.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>286.96</td>\n",
       "      <td>187.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>287.01</td>\n",
       "      <td>187.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>286.97</td>\n",
       "      <td>187.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>286.99</td>\n",
       "      <td>187.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>287.00</td>\n",
       "      <td>187.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>287.04</td>\n",
       "      <td>187.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   security price  option price\n",
       "0          286.99        187.99\n",
       "1          287.00        187.15\n",
       "2          286.99        187.15\n",
       "3          287.00        188.01\n",
       "4          286.96        187.15\n",
       "5          287.01        187.15\n",
       "6          286.97        187.15\n",
       "7          286.99        187.15\n",
       "8          287.00        187.13\n",
       "9          287.04        187.16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading in data\n",
    "df_100 = pd.read_csv(dir_path + \"SPY_US_09_21_18_C100_Equity_ask.dat\",\n",
    "                     delimiter=' ',  # The security price and option price is seperated by a space\n",
    "                     comment='#',  # Some lines have missing data and start with a #. I ignore these lines\n",
    "                     names=['security price', 'option price'])\n",
    "\n",
    "# Displaying first 10 rows of data\n",
    "display(df_100.head(10))\n",
    "\n",
    "assert_true(df_100.isnull().values.any() == False,\n",
    "           msg=\"You read in missing values. Check data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute_TE function\n",
    "\n",
    "In [compute_TE.cpp](https://github.com/ikegwukc/TransEnt/blob/master/src/compute_TE.cpp) there's a function called `compute_TE` which serves as the main function returning the transfer entropy. \n",
    "The following is done in the `compute_TE` function:\n",
    "1. A safety check to make sure that assumptions of Kraskov are not violated\n",
    "2. Dimensions for 4 subspaces are created:\n",
    "    - dimension of the xky space = look-back (embedding) + 2\n",
    "    - dimension of the ky space = embedding + 1\n",
    "    - dimension of the xk space = embedding + 1\n",
    "    - dimension of the k space = embedding \n",
    "3. KD-Trees & Arrays are initalized for for all of subspaces.\n",
    "4. Arrays are populated & KD-Trees are built for each space\n",
    "5. Transfer Entropy is calaculated using either a function to calculate the difference between mutual information or a function to calculate the  TE using a \"correlation\" approach.\n",
    "\n",
    "I will define this main function after I have the nessecary code to perform steps 1-5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Safety Check Function\n",
    "\n",
    "Taken from: https://github.com/ikegwukc/TransEnt/blob/master/man/computeTE.Rd#L51\n",
    "> A more subtle error can occur when multiple points in X^(k) (or some of its subspaces) have identical coordinates. This can lead to several points which have identical distance to a query point, which violates the assumptions of the Kraskov estimator, causing it to throw an error. The solution in this case is to add some small noise to the measurements \n",
    "\n",
    "In [compute_TE.cpp](https://github.com/ikegwukc/TransEnt/blob/master/src/compute_TE.cpp) there's a function called `safetyCheck` that checks for duplicate points in each column, if there are duplicate points the program stops and recommends that you add noise to your data.  \n",
    "\n",
    "In the first 10 rows displayed above:\n",
    "row 0 & 2 have the points in the security price column and row 1 & 2 have duplicate points in the option price column and so on. Ergo, if this data is used with compute_TE.cpp it will break and [compute_TE.cpp](https://github.com/ikegwukc/TransEnt/blob/master/src/compute_TE.cpp) will recommend that you use the `safetyCheck` function with your data which indicate that you need to add some noise to your data.\n",
    "\n",
    "In the code cell below I find all duplicate points for each column and add a small amount of noise to  the duplicate points.\n",
    "\n",
    "-----\n",
    "**Note:**\n",
    "- Ask about how McMullin handled this in R. \n",
    "    - Do they add a bit of noise to all points? Or just to duplicates?\n",
    "    - How do they handle duplicates?\n",
    "        - After first occurance or last occurance?\n",
    "    - In Section 3.2 of [1] they use noise from normal distribution for an example. For now I assume they use the standard normal distribution to generate noise with actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random number generator with a seed set to a constant for reproducability\n",
    "random_state = np.random.RandomState(seed=23)\n",
    "\n",
    "# Making a copy of the orginal data since we will modify it below\n",
    "df_100_bak = df_100.copy()\n",
    "\n",
    "# Find duplicates for security price column.\n",
    "dups = df_100.duplicated(subset=\"security price\", keep='first')\n",
    "\n",
    "# Select indicies where there a duplicates\n",
    "idx =  df_100.index[dups].tolist()\n",
    "\n",
    "# Select all of indicies where there are duplicate points\n",
    "# and add a random value to each duplicate point \n",
    "# from the standard normal distribution\n",
    "\n",
    "df_100['security price'].loc[idx] = np.add(df_100['security price'].loc[idx].values,\n",
    "                                           random_state.randn(len(idx)))\n",
    "\n",
    "# Next we will perform a check to make sure that\n",
    "# only the values with duplicate points were changed\n",
    "\n",
    "assert_array_equal(df_100['security price'] != df_100_bak['security price'], dups,\n",
    "                  err_msg=\"In addition to duplicate points you modified points that were different.\")\n",
    "\n",
    "# We will now add noise to duplicate points for the option price column.\n",
    "\n",
    "dups = df_100_bak.duplicated(subset=\"option price\", keep='first')  # Find duplicates\n",
    "\n",
    "idx =  df_100_bak.index[dups].tolist()  # select those indicies\n",
    "\n",
    "# add random noise to those industries\n",
    "df_100['option price'].loc[idx] = np.add(df_100['option price'].loc[idx].values,\n",
    "                                           random_state.randn(len(idx)))\n",
    "\n",
    "assert_array_equal(df_100['option price'] != df_100_bak['option price'], dups,\n",
    "                  err_msg=\"In addition to duplicate points you modified points that were different.\")\n",
    "\n",
    "# TODO:\n",
    "# Check for NaNs in either column\n",
    "# assert for length is same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below I write the data containing no duplicates to a csv file. I will use this to compute TE using R and measure the time it takes to run in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Writing to csv to compute in R to compare to final value.\n",
    "df_100.to_csv(\"./testData/df_100_nodup.csv\", index=False, sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MakeSpaces function\n",
    "\n",
    "In [compute_TE.cpp](https://github.com/ikegwukc/TransEnt/blob/master/src/compute_TE.cpp) there's a function called `MakeSpaces` which:\n",
    "1. Makes 4 subspaces:\n",
    "    -  xky subspace: contains the X values, the look back values for X, and the Y Values\n",
    "    - ky subspace: contains X values and Y Values\n",
    "    - xk subspace: contains lag \n",
    "    - k subspace: contains only X Values\n",
    "---\n",
    "1. Allocates empty points with a size of N by M\n",
    "    - Where N is the number of rows in X. \n",
    "    - Where M is a particular dimension for the xky, ky, xk, and k spaces.\n",
    "2. For each row the first column is the first value of X.\n",
    "3. Then each subsequent column is then the lag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.2 s, sys: 41.9 ms, total: 19.2 s\n",
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining how far we want to look back\n",
    "embedding = 1  # Must be greater than or equal to 1\n",
    "\n",
    "# Define the dimensions of each subspace\n",
    "dimxky =  embedding + 2\n",
    "dimky  =  embedding + 1\n",
    "dimxk  =  embedding + 1\n",
    "dimk   =  embedding\n",
    "\n",
    "N = len(df_100)  # Number of rows\n",
    "\n",
    "# Creating array of zeros with N rows and the apropriate amount of columns for each subspace\n",
    "xkyPts = np.zeros((N, dimxky))\n",
    "kyPts = np.zeros((N, dimky))\n",
    "xkPts = np.zeros((N, dimxk))\n",
    "kPts = np.zeros((N, dimk))\n",
    "\n",
    "nPts = 0\n",
    "X = df_100['security price']\n",
    "Y = df_100['option price']\n",
    "\n",
    "for i in range(embedding, len(X)):\n",
    "    t=0\n",
    "    xkyPts[nPts][t]=X[i]\n",
    "    xkPts[nPts][t]=X[i]\n",
    "    t+=1\n",
    "    j=1\n",
    "    for j in range(1, embedding+1):\n",
    "        xkyPts[nPts][t]=X[i-j]\n",
    "        xkPts[nPts][t]=X[i-j]\n",
    "        kyPts[nPts][t-1]=X[i-j]\n",
    "        kPts[nPts][t-1]=X[i-j]\n",
    "        t+=1\n",
    "    xkyPts[nPts][t]=Y[i-1]\n",
    "    kyPts[nPts][t-1]=Y[i-1]\n",
    "    nPts+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xkykdTree = KDTree(xkyPts)\n",
    "kykdTree = KDTree(kyPts)\n",
    "xkkdTree = KDTree(xkPts)\n",
    "kkdTree = KDTree(kPts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### TE_mutual_information_difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing TE:   0%|          | 353/191876 [30:30<275:56:04,  5.19s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# number of neighbors\n",
    "k = 1\n",
    "\n",
    "#variables to store the distance to the kth neighbor in different spaces\n",
    "tmpdist,xdistXKY,xdistXK,kydist,kdist = 0,0,0,0,0\n",
    "\n",
    "#counters for summing the digammas of the point counts.\n",
    "cntX_XKY, cntX_XK, cntKY_XKY, cntK_XK = 0,0,0,0\n",
    "\n",
    "\n",
    "# for each point in the XKY space,\n",
    "for i in tqdm(range(1, nPts),total=nPts-1, desc='Computing TE'):\n",
    "    # Returns distance and indicies of k nearest neighbors\n",
    "    dists, idxs = xkykdTree.query(xkyPts[i].reshape(1,-1), k=k+1)\n",
    "    idx = idxs[0, 1:]  # Drop first index since it is a duplicate\n",
    "    dists = dists[0, 1:]  # Drop first index since it is a duplicate\n",
    "    \n",
    "    \n",
    "    xdistXKY= abs(xkyPts[i][0] - xkyPts[idx].flatten()[0])\n",
    "    kydist= abs(xkyPts[i][1] - xkyPts[idx].flatten()[1])\n",
    "    \n",
    "    for j in range(2, dimxky):\n",
    "        tmpdist=abs(xkyPts[i][j] - xkyPts[idx].flatten()[j]);\n",
    "        if (tmpdist>kydist):\n",
    "            kydist=tmpdist\n",
    "    \n",
    "    # perform the same operations in the xk space\n",
    "\n",
    "    # Returns distance and indicies of k nearest neighbors\n",
    "    dists, idxs = xkkdTree.query(xkPts[i].reshape(1,-1), k=k+1)\n",
    "    idx = idxs[0, 1:]  # Drop first index since it is a duplicate\n",
    "    dists = dists[0, 1:]  # Drop first index since it is a duplicate\n",
    "    \n",
    "    \n",
    "    xdistXK= abs(xkPts[i][0] - xkPts[idx].flatten()[0])\n",
    "    kdist= abs(xkPts[i][1] - xkPts[idx].flatten()[1])\n",
    "    \n",
    "    for j in range(2, dimxk):\n",
    "        tmpdist=abs(xkPts[i][j] - xkPts[idx].flatten()[j]);\n",
    "        if (tmpdist>kydist):\n",
    "            kydist=tmpdist\n",
    "\n",
    "    # temp counters\n",
    "    Cnt1, Cnt2 = 0,0\n",
    "\n",
    "    for j in range(embedding, len(X)):\n",
    "        if( (abs(xkyPts[i][0] - X[j]) <= xdistXKY) and (abs(xkyPts[i][0] - X[j])!=0) ):\n",
    "            Cnt1+=1\n",
    "        if( (abs(xkPts[i][0]  - X[j]) <= xdistXK ) and (abs(xkPts[i][0]  - X[j])!=0) ):\n",
    "            Cnt2+=1\n",
    "    \n",
    "    # sum of digammas in different subspaces\n",
    "    cntX_XKY  += digamma(Cnt1)\n",
    "    cntX_XK   += digamma(Cnt2)\n",
    "    \n",
    "    #Count the number of points in the KY subspace, within the XKY distance:\n",
    "    Cnt1 = kykdTree.query_radius(kyPts[i].reshape(1,-1), kydist, count_only=True)\n",
    "    \n",
    "    if Cnt1 == 0:\n",
    "        Cnt=1\n",
    "    \n",
    "    cntKY_XKY += digamma(Cnt1)\n",
    "    \n",
    "    # and in the K subspace, using the XK distance:\n",
    "    Cnt2 = kkdTree.query_radius(kPts[i].reshape(1,-1), kdist, count_only=True)\n",
    "    if Cnt2 == 0:\n",
    "        Cnt2 = 1\n",
    "    \n",
    "    cntK_XK += digamma(Cnt2)\n",
    "    \n",
    "\n",
    "#    break\n",
    "TE = (cntX_XK + cntK_XK)/nPts - (cntX_XKY + cntKY_XKY)/nPts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kyPts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xkyPts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xkyPts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
